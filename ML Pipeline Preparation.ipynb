{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hider\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hider\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hider\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet','stopwords'])\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer , TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///data.db')\n",
    "df = pd.read_sql(\"SELECT * FROM Messages\", engine)\n",
    "\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "1        1        0      0            1             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                  0         0         0            0  ...            0   \n",
       "1                  0         0         0            0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "\n",
       "[2 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    INPUT\n",
    "    text - a String\n",
    "    \n",
    "    the function will make the texte to a loxer case \n",
    "    then it will delete all the special caracters \n",
    "    after that it will split it to a list of words \n",
    "    finally it will lemetize the list of words \n",
    "    \n",
    "    OUTPUT\n",
    "    a list of tokenized word \n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-z0-9]\",\" \",text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    clean_tokens = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for w in words:\n",
    "        clean_tok = lemmatizer.lemmatize(w , pos='v').strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(tokenizer=tokenize)\n",
    "X_vectorized = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, values = [], []\n",
    "for k, v in vect.vocabulary_.items():\n",
    "    keys.append(k)\n",
    "    values.append(v)\n",
    "\n",
    "vocabulary = pd.DataFrame.from_dict({'words': keys, 'counts': values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>anymore</td>\n",
       "      <td>2791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19391</td>\n",
       "      <td>ari</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22684</td>\n",
       "      <td>consignment</td>\n",
       "      <td>6689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28682</td>\n",
       "      <td>fmoh</td>\n",
       "      <td>10585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26393</td>\n",
       "      <td>frontloaders</td>\n",
       "      <td>10940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25241</td>\n",
       "      <td>kulob</td>\n",
       "      <td>15298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22009</td>\n",
       "      <td>matchboxes</td>\n",
       "      <td>16880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28223</td>\n",
       "      <td>ngouboua</td>\n",
       "      <td>18604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14564</td>\n",
       "      <td>oruconnect</td>\n",
       "      <td>19541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13805</td>\n",
       "      <td>palomacv</td>\n",
       "      <td>19874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15375</td>\n",
       "      <td>rayons</td>\n",
       "      <td>22026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11592</td>\n",
       "      <td>spanishdict</td>\n",
       "      <td>24987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6787</td>\n",
       "      <td>tjis</td>\n",
       "      <td>26702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17771</td>\n",
       "      <td>windbreaks</td>\n",
       "      <td>29015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18920</td>\n",
       "      <td>wvi</td>\n",
       "      <td>29228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words  counts\n",
       "535         anymore    2791\n",
       "19391           ari    3000\n",
       "22684   consignment    6689\n",
       "28682          fmoh   10585\n",
       "26393  frontloaders   10940\n",
       "25241         kulob   15298\n",
       "22009    matchboxes   16880\n",
       "28223      ngouboua   18604\n",
       "14564    oruconnect   19541\n",
       "13805      palomacv   19874\n",
       "15375        rayons   22026\n",
       "11592   spanishdict   24987\n",
       "6787           tjis   26702\n",
       "17771    windbreaks   29015\n",
       "18920           wvi   29228"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.sample(15, random_state=72).sort_values('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'related': 19906,\n",
       " 'request': 4474,\n",
       " 'offer': 118,\n",
       " 'aid_related': 10860,\n",
       " 'medical_help': 2084,\n",
       " 'medical_products': 1313,\n",
       " 'search_and_rescue': 724,\n",
       " 'security': 471,\n",
       " 'military': 860,\n",
       " 'child_alone': 0,\n",
       " 'water': 1672,\n",
       " 'food': 2923,\n",
       " 'shelter': 2314,\n",
       " 'clothing': 405,\n",
       " 'money': 604,\n",
       " 'missing_people': 298,\n",
       " 'refugees': 875,\n",
       " 'death': 1194,\n",
       " 'other_aid': 3446,\n",
       " 'infrastructure_related': 1705,\n",
       " 'transport': 1201,\n",
       " 'buildings': 1333,\n",
       " 'electricity': 532,\n",
       " 'tools': 159,\n",
       " 'hospitals': 283,\n",
       " 'shops': 120,\n",
       " 'aid_centers': 309,\n",
       " 'other_infrastructure': 1151,\n",
       " 'weather_related': 7297,\n",
       " 'floods': 2155,\n",
       " 'storm': 2443,\n",
       " 'fire': 282,\n",
       " 'earthquake': 2455,\n",
       " 'cold': 530,\n",
       " 'other_weather': 1376,\n",
       " 'direct_report': 5075}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic={}\n",
    "for co in Y.columns:\n",
    "   dic[co] = Y[co].sum()\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hider', 'toula', 'study', 'sorbonne', 'university']\n"
     ]
    }
   ],
   "source": [
    "hider = \"i'm hider toula and i am studying At Sorbonne University\"\n",
    "print(tokenize(hider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(DecisionTreeClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,test_size = 0.2, random_state = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features=None,\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        presort=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        splitter='best'),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(y_test, y_pred):\n",
    "    '''\n",
    "    INPUT\n",
    "    y_test : the labels of the data set \n",
    "    y_pred : the labels of the predction on the data set\n",
    "    \n",
    "    calculate the averge of fscor , recall , pressision for each categorie \n",
    "    OUTPUT\n",
    "    - fscore for each categorie \n",
    "    - recall for each categorie \n",
    "    - pressision for each categorie \n",
    "    '''\n",
    "    results = pd.DataFrame(columns=['Category', 'f_score', 'precision', 'recall'])\n",
    "    col = 0\n",
    "    for categorie in y_test.columns:\n",
    "        precision, recall, f_score, support = precision_recall_fscore_support(y_test[categorie], y_pred[:,col], average='weighted')\n",
    "        results.set_value(col+1, 'Category', categorie)\n",
    "        results.set_value(col+1, 'f_score', f_score)\n",
    "        results.set_value(col+1, 'precision', precision)\n",
    "        results.set_value(col+1, 'recall', recall)\n",
    "        col += 1\n",
    "    print('avrege of  f_score:', results['f_score'].mean())\n",
    "    print('avrege of precision:', results['precision'].mean())\n",
    "    print('avrege of recall:', results['recall'].mean())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avrege of  f_score: 0.9304399423434854\n",
      "avrege of precision: 0.9292884612094786\n",
      "avrege of recall: 0.931761429120246\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>related</td>\n",
       "      <td>0.771262</td>\n",
       "      <td>0.770043</td>\n",
       "      <td>0.77257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>request</td>\n",
       "      <td>0.847169</td>\n",
       "      <td>0.847238</td>\n",
       "      <td>0.8471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>offer</td>\n",
       "      <td>0.992204</td>\n",
       "      <td>0.991037</td>\n",
       "      <td>0.993469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aid_related</td>\n",
       "      <td>0.713469</td>\n",
       "      <td>0.713351</td>\n",
       "      <td>0.7136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>medical_help</td>\n",
       "      <td>0.903693</td>\n",
       "      <td>0.901086</td>\n",
       "      <td>0.906646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>medical_products</td>\n",
       "      <td>0.940025</td>\n",
       "      <td>0.939068</td>\n",
       "      <td>0.94103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.954343</td>\n",
       "      <td>0.951747</td>\n",
       "      <td>0.957357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>security</td>\n",
       "      <td>0.968072</td>\n",
       "      <td>0.969005</td>\n",
       "      <td>0.967153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>military</td>\n",
       "      <td>0.960656</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.963888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>child_alone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>water</td>\n",
       "      <td>0.955107</td>\n",
       "      <td>0.955586</td>\n",
       "      <td>0.954668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>food</td>\n",
       "      <td>0.941521</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>0.94103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>shelter</td>\n",
       "      <td>0.929388</td>\n",
       "      <td>0.928598</td>\n",
       "      <td>0.930273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>clothing</td>\n",
       "      <td>0.98561</td>\n",
       "      <td>0.985829</td>\n",
       "      <td>0.985401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>money</td>\n",
       "      <td>0.971344</td>\n",
       "      <td>0.970281</td>\n",
       "      <td>0.972532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>missing_people</td>\n",
       "      <td>0.978928</td>\n",
       "      <td>0.977746</td>\n",
       "      <td>0.980215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>refugees</td>\n",
       "      <td>0.95838</td>\n",
       "      <td>0.958443</td>\n",
       "      <td>0.958317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>death</td>\n",
       "      <td>0.954204</td>\n",
       "      <td>0.95287</td>\n",
       "      <td>0.95582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>other_aid</td>\n",
       "      <td>0.806453</td>\n",
       "      <td>0.8036</td>\n",
       "      <td>0.809451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>infrastructure_related</td>\n",
       "      <td>0.892022</td>\n",
       "      <td>0.887624</td>\n",
       "      <td>0.896658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>transport</td>\n",
       "      <td>0.930085</td>\n",
       "      <td>0.928439</td>\n",
       "      <td>0.931809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>buildings</td>\n",
       "      <td>0.941947</td>\n",
       "      <td>0.939805</td>\n",
       "      <td>0.944679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>electricity</td>\n",
       "      <td>0.974576</td>\n",
       "      <td>0.973978</td>\n",
       "      <td>0.975221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>tools</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>0.991771</td>\n",
       "      <td>0.992509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>0.981136</td>\n",
       "      <td>0.979268</td>\n",
       "      <td>0.983096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>shops</td>\n",
       "      <td>0.993181</td>\n",
       "      <td>0.993086</td>\n",
       "      <td>0.993277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>aid_centers</td>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.979731</td>\n",
       "      <td>0.980407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>0.925436</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.929889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>weather_related</td>\n",
       "      <td>0.852506</td>\n",
       "      <td>0.852743</td>\n",
       "      <td>0.852286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>floods</td>\n",
       "      <td>0.931072</td>\n",
       "      <td>0.930566</td>\n",
       "      <td>0.931617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>storm</td>\n",
       "      <td>0.934364</td>\n",
       "      <td>0.934423</td>\n",
       "      <td>0.934307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>fire</td>\n",
       "      <td>0.984985</td>\n",
       "      <td>0.983938</td>\n",
       "      <td>0.986362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.962647</td>\n",
       "      <td>0.962543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>cold</td>\n",
       "      <td>0.975185</td>\n",
       "      <td>0.974475</td>\n",
       "      <td>0.975989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>other_weather</td>\n",
       "      <td>0.916375</td>\n",
       "      <td>0.910293</td>\n",
       "      <td>0.92355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0.796348</td>\n",
       "      <td>0.79426</td>\n",
       "      <td>0.798694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Category   f_score precision    recall\n",
       "1                  related  0.771262  0.770043   0.77257\n",
       "2                  request  0.847169  0.847238    0.8471\n",
       "3                    offer  0.992204  0.991037  0.993469\n",
       "4              aid_related  0.713469  0.713351    0.7136\n",
       "5             medical_help  0.903693  0.901086  0.906646\n",
       "6         medical_products  0.940025  0.939068   0.94103\n",
       "7        search_and_rescue  0.954343  0.951747  0.957357\n",
       "8                 security  0.968072  0.969005  0.967153\n",
       "9                 military  0.960656    0.9585  0.963888\n",
       "10             child_alone         1         1         1\n",
       "11                   water  0.955107  0.955586  0.954668\n",
       "12                    food  0.941521  0.942076   0.94103\n",
       "13                 shelter  0.929388  0.928598  0.930273\n",
       "14                clothing   0.98561  0.985829  0.985401\n",
       "15                   money  0.971344  0.970281  0.972532\n",
       "16          missing_people  0.978928  0.977746  0.980215\n",
       "17                refugees   0.95838  0.958443  0.958317\n",
       "18                   death  0.954204   0.95287   0.95582\n",
       "19               other_aid  0.806453    0.8036  0.809451\n",
       "20  infrastructure_related  0.892022  0.887624  0.896658\n",
       "21               transport  0.930085  0.928439  0.931809\n",
       "22               buildings  0.941947  0.939805  0.944679\n",
       "23             electricity  0.974576  0.973978  0.975221\n",
       "24                   tools  0.992128  0.991771  0.992509\n",
       "25               hospitals  0.981136  0.979268  0.983096\n",
       "26                   shops  0.993181  0.993086  0.993277\n",
       "27             aid_centers  0.980067  0.979731  0.980407\n",
       "28    other_infrastructure  0.925436  0.921233  0.929889\n",
       "29         weather_related  0.852506  0.852743  0.852286\n",
       "30                  floods  0.931072  0.930566  0.931617\n",
       "31                   storm  0.934364  0.934423  0.934307\n",
       "32                    fire  0.984985  0.983938  0.986362\n",
       "33              earthquake  0.962594  0.962647  0.962543\n",
       "34                    cold  0.975185  0.974475  0.975989\n",
       "35           other_weather  0.916375  0.910293   0.92355\n",
       "36           direct_report  0.796348   0.79426  0.798694"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_results(Y_test, Y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters =  {'tfidf__use_idf': (True,False)} \n",
    "cv = GridSearchCV(pipeline,parameters,cv=2,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        tok...\n",
       "                                                                                               max_leaf_nodes=None,\n",
       "                                                                                               min_impurity_decrease=0.0,\n",
       "                                                                                               min_impurity_split=None,\n",
       "                                                                                               min_samples_leaf=1,\n",
       "                                                                                               min_samples_split=2,\n",
       "                                                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                                                               presort=False,\n",
       "                                                                                               random_state=None,\n",
       "                                                                                               splitter='best'),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'tfidf__use_idf': (True, False)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model1.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect',TfidfVectorizer(tokenizer=tokenize)),\n",
    "    ('clf',  MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__smooth_idf': [True,False],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline,param_grid=parameters,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_...\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                                           base_estimator=None,\n",
       "                                                                                           learning_rate=1.0,\n",
       "                                                                                           n_estimators=50,\n",
       "                                                                                           random_state=None),\n",
       "                                                              n_jobs=None))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'vect__smooth_idf': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avrege of  f_score: 0.9398941635791375\n",
      "avrege of precision: 0.9398786828768078\n",
      "avrege of recall: 0.9475444999359711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>f_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>related</td>\n",
       "      <td>0.758802</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.796005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>request</td>\n",
       "      <td>0.881127</td>\n",
       "      <td>0.880927</td>\n",
       "      <td>0.889166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>offer</td>\n",
       "      <td>0.99261</td>\n",
       "      <td>0.990417</td>\n",
       "      <td>0.994814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>aid_related</td>\n",
       "      <td>0.746326</td>\n",
       "      <td>0.752199</td>\n",
       "      <td>0.751441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>medical_help</td>\n",
       "      <td>0.919942</td>\n",
       "      <td>0.920368</td>\n",
       "      <td>0.932194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>medical_products</td>\n",
       "      <td>0.953888</td>\n",
       "      <td>0.953644</td>\n",
       "      <td>0.960814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.961711</td>\n",
       "      <td>0.969458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>security</td>\n",
       "      <td>0.974824</td>\n",
       "      <td>0.971889</td>\n",
       "      <td>0.981752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>military</td>\n",
       "      <td>0.966537</td>\n",
       "      <td>0.965737</td>\n",
       "      <td>0.970803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>child_alone</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>water</td>\n",
       "      <td>0.962049</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>0.963312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>food</td>\n",
       "      <td>0.943981</td>\n",
       "      <td>0.943167</td>\n",
       "      <td>0.946024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>shelter</td>\n",
       "      <td>0.937603</td>\n",
       "      <td>0.936697</td>\n",
       "      <td>0.942182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>clothing</td>\n",
       "      <td>0.989123</td>\n",
       "      <td>0.988762</td>\n",
       "      <td>0.989627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>money</td>\n",
       "      <td>0.974788</td>\n",
       "      <td>0.973618</td>\n",
       "      <td>0.978871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>missing_people</td>\n",
       "      <td>0.981903</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>0.986554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>refugees</td>\n",
       "      <td>0.965462</td>\n",
       "      <td>0.963454</td>\n",
       "      <td>0.970227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>death</td>\n",
       "      <td>0.962302</td>\n",
       "      <td>0.963081</td>\n",
       "      <td>0.967345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>other_aid</td>\n",
       "      <td>0.835103</td>\n",
       "      <td>0.839397</td>\n",
       "      <td>0.870342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>infrastructure_related</td>\n",
       "      <td>0.910873</td>\n",
       "      <td>0.904855</td>\n",
       "      <td>0.931617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>transport</td>\n",
       "      <td>0.945374</td>\n",
       "      <td>0.946578</td>\n",
       "      <td>0.956781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>buildings</td>\n",
       "      <td>0.948239</td>\n",
       "      <td>0.947652</td>\n",
       "      <td>0.955244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>electricity</td>\n",
       "      <td>0.978701</td>\n",
       "      <td>0.977653</td>\n",
       "      <td>0.981176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>tools</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>0.989651</td>\n",
       "      <td>0.994237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>0.983185</td>\n",
       "      <td>0.980054</td>\n",
       "      <td>0.987322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>shops</td>\n",
       "      <td>0.994528</td>\n",
       "      <td>0.993095</td>\n",
       "      <td>0.995966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>aid_centers</td>\n",
       "      <td>0.984575</td>\n",
       "      <td>0.983106</td>\n",
       "      <td>0.988091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>0.93884</td>\n",
       "      <td>0.934992</td>\n",
       "      <td>0.953707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>weather_related</td>\n",
       "      <td>0.870303</td>\n",
       "      <td>0.875126</td>\n",
       "      <td>0.87572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>floods</td>\n",
       "      <td>0.951073</td>\n",
       "      <td>0.953055</td>\n",
       "      <td>0.955436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>storm</td>\n",
       "      <td>0.933623</td>\n",
       "      <td>0.933607</td>\n",
       "      <td>0.939109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>fire</td>\n",
       "      <td>0.984096</td>\n",
       "      <td>0.983392</td>\n",
       "      <td>0.988091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>0.971418</td>\n",
       "      <td>0.971201</td>\n",
       "      <td>0.971955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>cold</td>\n",
       "      <td>0.97941</td>\n",
       "      <td>0.978859</td>\n",
       "      <td>0.981944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>other_weather</td>\n",
       "      <td>0.925564</td>\n",
       "      <td>0.921639</td>\n",
       "      <td>0.94199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>0.835855</td>\n",
       "      <td>0.840333</td>\n",
       "      <td>0.852286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Category   f_score precision    recall\n",
       "1                  related  0.758802  0.772152  0.796005\n",
       "2                  request  0.881127  0.880927  0.889166\n",
       "3                    offer   0.99261  0.990417  0.994814\n",
       "4              aid_related  0.746326  0.752199  0.751441\n",
       "5             medical_help  0.919942  0.920368  0.932194\n",
       "6         medical_products  0.953888  0.953644  0.960814\n",
       "7        search_and_rescue  0.962222  0.961711  0.969458\n",
       "8                 security  0.974824  0.971889  0.981752\n",
       "9                 military  0.966537  0.965737  0.970803\n",
       "10             child_alone         1         1         1\n",
       "11                   water  0.962049  0.961297  0.963312\n",
       "12                    food  0.943981  0.943167  0.946024\n",
       "13                 shelter  0.937603  0.936697  0.942182\n",
       "14                clothing  0.989123  0.988762  0.989627\n",
       "15                   money  0.974788  0.973618  0.978871\n",
       "16          missing_people  0.981903  0.982265  0.986554\n",
       "17                refugees  0.965462  0.963454  0.970227\n",
       "18                   death  0.962302  0.963081  0.967345\n",
       "19               other_aid  0.835103  0.839397  0.870342\n",
       "20  infrastructure_related  0.910873  0.904855  0.931617\n",
       "21               transport  0.945374  0.946578  0.956781\n",
       "22               buildings  0.948239  0.947652  0.955244\n",
       "23             electricity  0.978701  0.977653  0.981176\n",
       "24                   tools  0.991939  0.989651  0.994237\n",
       "25               hospitals  0.983185  0.980054  0.987322\n",
       "26                   shops  0.994528  0.993095  0.995966\n",
       "27             aid_centers  0.984575  0.983106  0.988091\n",
       "28    other_infrastructure   0.93884  0.934992  0.953707\n",
       "29         weather_related  0.870303  0.875126   0.87572\n",
       "30                  floods  0.951073  0.953055  0.955436\n",
       "31                   storm  0.933623  0.933607  0.939109\n",
       "32                    fire  0.984096  0.983392  0.988091\n",
       "33              earthquake  0.971418  0.971201  0.971955\n",
       "34                    cold   0.97941  0.978859  0.981944\n",
       "35           other_weather  0.925564  0.921639   0.94199\n",
       "36           direct_report  0.835855  0.840333  0.852286"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = get_results(Y_test, y_pred)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at 0x0000017DF1902318>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                    base_estimator=None,\n",
       "                                                                    learning_rate=1.0,\n",
       "                                                                    n_estimators=50,\n",
       "                                                                    random_state=None),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(cv, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
